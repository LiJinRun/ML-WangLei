{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYtloXVU2geC"
   },
   "source": [
    "6.1 考察平面上的6个数据采样:\n",
    "$$\n",
    "x^{(1)} = (-1, 0),\\qquad y^{(1)} = +1\\\\  \n",
    "x^{(2)} = (-1, 1), \\qquad    y^{(2)} = +1\\\\\n",
    "x^{(3)} = (0, 1), \\qquad   y^{(3)} = +1\\\\\n",
    "x^{(4)} = (1, 0), \\qquad    y^{(4)} = -1\\\\\n",
    "x^{(5)} = (1, -1),  \\qquad   y^{(5)} = -1\\\\\n",
    "x^{(6)} = (0, -1), \\qquad    y^{(6)} = -1\\\\\n",
    "$$\n",
    "请计算这6个数据采样的最大间隔分离平面，并指出相应的支持向重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZRfz9Mc2geE"
   },
   "source": [
    "最大间隔分离平面是$x_1-x_2=0$，支持向量为$(0,1),(-1,0),(0,-1),(1,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGef8a8b2geG"
   },
   "source": [
    "6.2 设$S$是一组训练数据，且正负采样之间存在分离平面。设$L$是一个间隔最大的分离平面。请证明$L$的支持向量中一定既有正采样又有负采样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0-LpqcammQ_"
   },
   "source": [
    "如果只有正采样或者只有负采样，那么L就不是间隔最大的分离平面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_N9Gp0gd2geL"
   },
   "source": [
    "6.3 类别预测的置信度  \n",
    "  \n",
    "$Logistic$回归算法基于概率预测来完成类别预测任务，从而可以用概率来表示类别预测的置信度：样本属于某类别的概率预测值越大， 则将其归为该类别的置信度就越高。然而， 支持向量机直接完成类别预测任务，并不进行概率预测。那么，应当如何表示支持向量机算法的类别预测置信度呢？一个常用的方法是通过样本与分离平面之间的距离来表示置信度：距离越大，置信度就越高。请在图6.6的支持向量机算法中增加一个函数$predict_confidence$来完成对置信度的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YLb5-An2geM"
   },
   "outputs": [],
   "source": [
    "def predict_confidence(self, X, y):\n",
    "    return sigmoid(np.abs(X.dot(self.w) + self.b) / np.sqrt(np.sum(w**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bi6U6J402geS"
   },
   "source": [
    "6.4 One-versus-All 方法   \n",
    "  One-versus-All方法是一 种用二元分类问题的算法来求解$k$元分类问题的重要手段。设A是一个二元分类问题算法。对于一个给定的$k$元分类问题，设其标签类别为$1,2,\\dots ,k$。对每一个元分类问题算法。对于一个给定的$k$元分类问题，设其标签类别为$1,2,\\dots ,k$。对每一个$1≤i≤k$，考虑如下二元分类问题:如果样本的类别等于$i$，则生成标签+1,否则生成标签-1.对如此定义的一个二元分类问题,用算法A训练出一个模型$h_i$:对任意一个样本$x,h_i(x)$表示x属于类别i的概率(或者说置信度)。依此方法可以得到k个模型$h_i,h_2,\\dots h_k$。 对一个样本x，One-versus AlI方法预测$x$所属的类别为\n",
    "$$\n",
    "\\arg \\max \\limits_{1\\leq i\\leq k}{h_i(x)} \n",
    "$$\n",
    "请结合习题6.3， 实现One-versus-All方法,从而将支持向量机算法拓展到$k$元分类问题中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LY2JHqvq2geT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SVM:\n",
    "    def get_H(self, Lambda, i, j, y):\n",
    "        if y[i]==y[j]:\n",
    "            return Lambda[i] + Lambda[j]\n",
    "        else:\n",
    "            return float(\"inf\")\n",
    "    \n",
    "    def get_L(self, Lambda, i, j, y):\n",
    "        if y[i]==y[j]:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return max(0, Lambda[j] - Lambda[i])\n",
    "            \n",
    "    def smo(self, X, y, K, N):\n",
    "        m, n = X.shape\n",
    "        Lambda = np.zeros((m,1))\n",
    "        epsilon = 1e-6\n",
    "        for t in range(N):\n",
    "            for i in range(m):\n",
    "                for j in range(m):\n",
    "                    D_ij = 2 * K[i][j] - K[i][i] - K[j][j]\n",
    "                    if abs(D_ij) < epsilon:\n",
    "                        continue\n",
    "                    E_i = K[:, i].dot(Lambda * y) - y[i]\n",
    "                    E_j = K[:, j].dot(Lambda * y) - y[j]\n",
    "                    delta_j = 1.0 * y[j] * (E_j - E_i) / D_ij\n",
    "                    H_ij = self.get_H(Lambda, i, j, y)\n",
    "                    L_ij = self.get_L(Lambda, i, j, y)\n",
    "                    if Lambda[j] + delta_j > H_ij:\n",
    "                        delta_j = H_ij - Lambda[j]\n",
    "                        Lambda[j] = H_ij\n",
    "                    elif Lambda[j] + delta_j < L_ij:\n",
    "                        delta_j = L_ij - Lambda[j]\n",
    "                        Lambda[j] = L_ij\n",
    "                    else:\n",
    "                        Lambda[j] += delta_j\n",
    "                    delta_i = - y[i] * y[j] * delta_j\n",
    "                    Lambda[i] += delta_i\n",
    "                    if Lambda[i] > epsilon:\n",
    "                        b = y[i] - K[:, i].dot(Lambda * y)\n",
    "                    elif Lambda[j] > epsilon:\n",
    "                        b = y[j] - K[:, j].dot(Lambda * y)\n",
    "        self.Lambda = Lambda\n",
    "        self.b = b\n",
    "        \n",
    "    def fit(self, X, y, N = 10):\n",
    "        K = X.dot(X.T)\n",
    "        self.smo(X, y, K, N)\n",
    "        self.w = X.T.dot(self.Lambda * y)\n",
    "        \n",
    "    def predict_confidence(self, X):\n",
    "        return sigmoid(np.abs(X.dot(self.w) + self.b) / np.sqrt(np.sum(w**2)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.sign(X.dot(self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vQSaAPr2geX"
   },
   "outputs": [],
   "source": [
    "# 有k个类,标签分别是1,2,3...k\n",
    "def SVM_OVA(X_train, y_train, X_test)\n",
    "    confidences = np.zeros((len(X_test), 1))\n",
    "    for i in range(1,k+1):\n",
    "        y_train_copy = y_train.copy() # 重新copy一份标签副本\n",
    "        y_train_copy[y_train_copy == i] = 1  # 将标签是i的置为1\n",
    "        y_train_copy[y_train_copy != i] = -1 # 将标签不是i的置为-1\n",
    "        model = SVM()\n",
    "        model.fit(X_train, y_train_copy) # 训练模型\n",
    "        confidence = model.predict_confidence(X_test) # 计算置信度\n",
    "        confidences = np.concatenate((confidences, confidence), axis=1) # 添加第i个模型的分类置信度\n",
    "    y_pred = np.argmax(confidences, axis=1) # 预测结果\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQneWc5q2gea"
   },
   "source": [
    "6.5 设$K_1(x,z$和$K_2(x, z)$是两个核函数，$a>0$是一个正实数。请证明  \n",
    "(1) $K(x, z) = K_1(x, z) + K_2(x,z)$也是一个核函数。  \n",
    "(2) $K(x, z) = aK_1(x, z)$ 也是一个核函数。  \n",
    "(3) $K(x, z) = K_1(x, z)K_2(x,z)$也是一个核函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fV7iBxO52geb"
   },
   "source": [
    "因为$K_1(x,z)和K_2(x,z)$是两个核函数，所以$K_1=(K_{1ij})_{1\\le i,j\\le m},K_2=(K_{2ij})_{1\\le i,j\\le m}$为半正定矩阵，即对任意向量$z$，有$z^TK_1z\\ge 0,z^TK_2z\\ge 0$\n",
    "\n",
    "（1）因为$z^T(K_1+K_2)z=z^TK_1z+z^TK_2z\\ge0$，所以$K(x,z)=K_1(x,z)+K_2(x,z)$是核函数\n",
    "\n",
    "（2）因为$\\alpha>0$所以$\\alpha z^TK_1z\\ge0$，所以$K(x,z)=\\alpha K_1(x,z)$是核函数\n",
    "\n",
    "（3）因为\n",
    "$$\n",
    "z^TK_1K_2z=\\sum_{i,j,k=1}^m z_iK_{1ij}K_{2jk}z_k\n",
    "=\\sum_{i,j,k=1}^m z_i\\langle\\phi_1(x^{(i)}),\\phi_1(x^{(j)})\\rangle \\langle \\phi_2(x^{(j)}),\\phi_2(x^{(k)})\\rangle z_k\\\\\n",
    "=\\sum_{i,j,k=1}^m z_i(\\sum_{t=1}^N\\phi_{1t}(x^{(i)})\\phi_{1t}(x^{(j)})) (\\sum_{t=1}^N\\phi_{2t}(x^{(j)})\\phi_{2t}(x^{(k)}))  z_k\\\\\n",
    "=\\sum_{i,j=1}^m  z_i(\\sum_{t=1}^N\\phi_{1t}(x^{(i)})\\phi_{1t}(x^{(j)})) \\sum_{j,k=1}^m(\\sum_{t=1}^N\\phi_{2t}(x^{(j)})\\phi_{2t}(x^{(k)}))  z_k \\\\\n",
    "=\\sum_{t=1}^N \\sum_{i,j,k=1}^m z_i \\phi_{1t}(x^{(i)})\\phi_{1t}(x^{(j)})\\phi_{2t}(x^{(j)})\\phi_{2t}(x^{(k)})z_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIk_yNhf2geb"
   },
   "source": [
    "6.6 图6.20 实现了软间隔支持向量机的次梯度下降算法。请修改图6.20中的算法以实现软间隔支持向量机的随机梯度下降算法。\n",
    "![6.20.png](6.20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ntk4vCVh2gec"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SoftSVM:\n",
    "    def __init__(self, C=1000):\n",
    "        self.C = C\n",
    "    def fit(self, X, y, eta=0.01, N=5000):\n",
    "        m, n = X.shape\n",
    "        w, b = np.zeros((n, 1)), 0\n",
    "        for r in range(N):\n",
    "            i = np.random.randint(m)\n",
    "            x = X[i].reshape(1,-1)\n",
    "            s = (x.dot(w) + b) * y\n",
    "            e = (s < 1).astype(np.int).reshape(-1,1)\n",
    "            g_w = -1/m * x.T.dot(y * e) + 1 / (m * self.C) * w\n",
    "            g_b = -1/m * (y * e).sum()\n",
    "            w = w - eta * g_w\n",
    "            b = b - eta * g_b\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    def predict(self, X):\n",
    "        return np.sign(X.dot(self.w)+self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0GCjdY32geh"
   },
   "source": [
    "6.7 图6.16是软间隔支持向量机的SMO算法。由于该算法只涉及内积计算.所以核方法也可以用到软间隔支持向量机中。请修改图6.16中的算法以实现软间隔支持向量机的核方法。\n",
    "![6.16.png](6.16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkmJmtqx2gei"
   },
   "outputs": [],
   "source": [
    "from machine_learning.lib.svm_smo import SVM\n",
    "\n",
    "class SoftSVM(SVM):\n",
    "    def __init__(self, C=1000, kernel=None):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def get_H(self, Lambda, i, j, y):\n",
    "        C = self.C\n",
    "        if y[i] == y[j]:\n",
    "            return min(C, Lambda[i] + Lambda[j])\n",
    "        else:\n",
    "            return min(C, C+Lambda[j]-Lambda[i])\n",
    "        \n",
    "    def get_L(self, Lambda, i, j, y):\n",
    "        if y[i] == y[j]:\n",
    "            return max(0, Lambda[i]+Lambda[j]-self.C)\n",
    "        else:\n",
    "            return max(0, Lambda[j]-Lambda[i])\n",
    "    \n",
    "    def get_K(self, X_1, X_2):\n",
    "        if self.kernel == None:\n",
    "            return X_1.dot(X_2.T)\n",
    "        m1, m2 = len(X_1), len(X_2)\n",
    "        K = np.zeros((m1, m2))\n",
    "        for i in range(m1):\n",
    "            for j in range(m2):\n",
    "                K[i][j] = self.kernel(X_1[i], X_2[j])\n",
    "        return K\n",
    "    \n",
    "    def fit(self, X, y, N=10):\n",
    "        K = self.get_K(X, X)\n",
    "        self.smo(X, y, K, N)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        K = self.get_K(X, self.X_train)\n",
    "        return np.sign(K.dot(self.Lambda*self.y_train)+self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZ4LuRIy2gel"
   },
   "source": [
    "6.8 第2章介绍过感知器算法。在感知器算法中，如果发现一个负采样$(x^{(i)}, y^{(i)})$位于当前直线$\\left \\langle w, x \\right \\rangle + b$ 的上方.则以如下的方式更新模型参数:\n",
    "$$\n",
    "w \\leftarrow w + y^{(i)} x^{(i)} \\\\\n",
    "b \\leftarrow b + y^{(i)}\n",
    "$$\n",
    "类似地，当发现一个正采样位于当前直线的下方时，也以用上述方式更新参数值。请问，应当如何将核方法运用到感知器算法中?请描述并实现感知器算法的核方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJ0GivWC2gel"
   },
   "source": [
    "基于核函数的非线性判别函数为\n",
    "$$\n",
    "f^H(x)=\\sum_{i=1}^m \\lambda_i y^{(i)}K(x^{(i)},x)+b\n",
    "$$\n",
    "if $f^H(x^{(k)})y^{(k)}<0$  \n",
    "then $\\lambda_i \\leftarrow \\lambda_i + y^{(i)}y^{(k)}K(x^{(i)},x^{(k)})$   \n",
    "$\\quad b \\leftarrow b + y^{(k)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmh5188o2gem"
   },
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel=None):\n",
    "        self.kernel = kernel\n",
    "    def get_K(self, X_1, X_2):\n",
    "        if self.kernel == None:\n",
    "            return X_1.dot(X_2.T)\n",
    "        m1, m2 = len(X_1), len(X_2)\n",
    "        K = np.zeros((m1, m2))\n",
    "        for i in range(m1):\n",
    "            for j in range(m2):\n",
    "                K[i][j] = self.kernel(X_1[i], X_2[j])\n",
    "        return K\n",
    "    def fit(self, X, y):\n",
    "        K = self.get_K(X, X)\n",
    "        m, _ = X.shape\n",
    "        Lambda = np.zeros((m,1))\n",
    "        b = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            done = True\n",
    "            for i in range(m):\n",
    "                x = X[i].reshape(1, -1)\n",
    "                for k in range(m):\n",
    "                    if y[k] * (np.sum(Lambda[i] * y[i] * K[i][k]) + b) < =:\n",
    "                        Lambda[i] = Lambda[i] + y[i]*y[k]*K[i][k]\n",
    "                        b = b + y[k]\n",
    "        self.Lambda = Lambda\n",
    "        self.b = b\n",
    "    def predict(self, X):\n",
    "        K = self.get_K(X, self.X_train)\n",
    "        return np.sign(K.dot(self.Lambda*self.y_train)+self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkMsJOBm2gep"
   },
   "source": [
    "6.9 国际政治家面部识别\n",
    "在 Sklearn 的数据库中集成了一组由7位国际政治家 Ariel Sharon、Colin Powell、Donald Rumsfeld、George Bush、Gerhard Schroder、Hugo Chavez 和 Tony Blair 的面部组成的图片集。图6.21是4幅图片采样，从左到右分别为 Gerhard Schroder、George Bush、Colin Powell 和 Tony Blair。  \n",
    "![6.21](6.21.png)  \n",
    "在Sklearn数据集中有1288条数据。每条数据的特征组是-个1850 维的向量。数据表示的是一一个50X37的图片像素灰度矩阵。标签是一个0-6的整数,分别表示7位政治家。图6.22是获取与观察数据的程序。第2行导入获取数据的函数fetch_lfw_people。第5行调用该函数读取数据。第6行打印target_names,从而可以获得标签与人名的对应关系，例如标签3对应George Bush。第7.8行分别获取特征与标签。第10-12行打印出一张图片。  \n",
    "![6.22](6.22.png)  \n",
    "基于这一数据集,请对每一位政治家完成如下任务: 给定一张图片，预测图片中的人物是否为这位政治家。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "wNLZ52JP2geq",
    "outputId": "0efcf395-6a3b-48e8-d629-4e1ff3e3f16c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
      "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Tony Blair']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAD6CAYAAADzyJjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2da6il53Xff2vfz5mZMzNnNJqORnKkRCZBNLFdBuGQfihyBa5bKn0wIaYUBQT60haHpNRKCwVDPzgfGrfQNkHUJiqEyIljkAhpjGoUgqHIViw7sSXbuhRbl5HG0mgu57Kv79MPZ0vnPP9nzXlfzWWfM876wTDnec9z23uftd+13rWetSylRBD8Xae11xsIgv1ACEIQEIIQBEAIQhAAIQhBAIQgBAFwlYJgZh83sx+Y2Ytm9vC12lQQLBq7Uj+CmbWBHwL3Aq8C3wQ+lVJ67nJjblptp9tv6+46byLfzzhVWfvHo9VizHCYz9npzbL2Umey65oAFVZc0yv6TlWpHJPkms7rvd1Ws5D3Cek62kd/73FFfSq/3+6TeNd2n7eVf4Rb1+RjbI3ziVtTZ3Oz/NrF8ZtvpZSOa7eOs8Wm3A28mFJ6GcDMHgPuAy4rCLff1uUbX71t10knKX8HfjzdzNr/5uVfLcY8//1bs/bxD7yTtX/x2Jld1wTYnJUC2rL8jZ6m/AY6nJZjxlU7n1f6zKryJtxu5R+W/vFNnTHjWb7OdJb3mcjvAapKhFTmnU3LdaaTfJ40kT6VI0z69+gInI3za+2NfN7BuXLM8hv553Hw1XHW7r29UYxpXcyv/cXL//lHRSeuTjU6Bbyyo/3q/FoQ3HBcd2PZzB4ys2fM7JmfvO3c74JgH3A1qtFrwE4959b5tYyU0iPAIwCnPzTI7m2qBgGsVaOs/ZVLH8ra33/OUa06+b14dSm/HU6Sc8sXFcazEVzdtga1G1S9SlZOqmqOzuGpU6NJZ9c+U0fNKewKtUU8FaYl+281MGDU6PHsIlGpipW9MTO5qIMKYwtSu9l3/dXcEb4JfNDM7jCzHvBrwBNXMV8Q7BlXfEdIKU3N7F8DXwXawBdTSt+7ZjsLggVyNaoRKaU/B/78Gu0lCPaM8CwHAVd5R3i/jNKMlyZr77Vfmx0s+jy98YtZ+398/WNZ+9izpexeujf3Naz2c2NZDWOA4az+pXdau3uP1K8AMHOu1aGGrhrLk2m5f/UbqE9AfQZeH+/5foHap/V2cDlm5hjh05p1na11RuJAG8vn4znUGhJ3hCAgBCEIgBCEIAAWbCO8PjnMZ1//xHvtvz17S9Hn/JmVrH30O7l+PBuUyuPJoxez9tq0X7sX1cM75umX+TWN+fGC7hTV/0deDFDNPDPn97OZxglJTJAzT5qpQ62Jwr/7HH6skTjLxmWf1lT6aEBd7lcFoLOZfx7tYW5otDaG5aBN55pD3BGCgBCEIABCEIIAWLCNsH5xiW9+9e+/1+5eLPusruWKak/ab3601OVPyMEbDWLTwDeAQTsf02vXR8bqPDoHQE9OlFyoBlm7yXmEwq/gjNHn+a22nGnw/AhqnshbWej/QNLgPe3j+QgmEng4qfcjtId5n97F8jNrD3XD0qcq/zbStFnEc9wRgoAQhCAAQhCCAAhBCAJgwcZyawwHXtth4Dg+rM5QslgczI2owS1r1KGGb69VRnipUdtvl30mYl122vVBXRrMd6ArB8y99AzC+qSXtTcdY79VBASKg80xltWAVkM4TeudY4WzzDOWZ9qnnFb76HOH3lr5XmuQnWmQnZMixBZwQi0IfmoIQQgCQhCCAFiwjWAJ2juCqdpjx2ki1y7+bC6rN6+UNsJA9PuBONi8oDbNWqH2gDfOzXQhbExz/V4P9zTJujcSO6PXKe0XdbKNxGmlQXkAlSbn0raj7ysmdkRrWK6jGenaTtBdmQRM1nHMsdZEjA21CdrlZ0in2Z943BGCgBCEIABCEIIACEEIAmDRxvIMepe2raC2ZiEAZj3JOH08N5DUEAZY6eVZLNrigFLjsylF1Ko0NfO1N0adeV5mjLVJfqJuIoZwr1N6pDZGcnJPjGMvkhQZUzjDGiSBKIxlJxuFGse1GSscqq7jEGztbsynrvM514x5r1ujXkHwU04IQhAQghAEwMJthETvwrbCaFXpUFMbIR2q17H7Esim1W+8E2qFs6xBRgp1lnmZ7vTUms57frRUjFEbRsesj/J1AYabshetbOM41BRNUW+ePq3ZJtRccTJf6FvpZGt3BjXoIgF0Nhbjw6vL5TnZHOKOEASEIAQBEIIQBMDCbYSK7sUdUXdaCggYreb6/fJKnqnMyxxxSTLbNdH/x9XuermHZrprkvlaD9msj0t9X9kc5+/B5kaZua8SH0CrLe+lF6gnOnYai13hHWyR12gSZOeYX8XFyqsoLO+3SZ/JkpPdr5+v3RH937M5bdLMiRF3hCAgBCEIgBCEIAAaCIKZfdHMzprZd3dcWzWzJ83shfn/R6/vNoPg+tLEWP4D4L8B/2vHtYeBr6WUPmdmD8/bn6mbyBLYjlTe5hhnk+XcSFpZzo3lC+PSITWRFI+aQtFzqG1OcutMDWGoN6B1HYA1cmN4Q5xhWvIJyvTs6hxz15ba0iZ7cdNEao3krqSJ9FI+ihGubXW4NUXnqfr5PKPVct7uZv6Z9S7kbRs6ueRH4/KaQ+0dIaX0V8A5uXwf8Oj850eB+xutFgT7lCt9fHoipXRm/vMbwInLdTSzh4CHAAbdlct1C4I95aqN5bT18PmykSIppUdSSqdTSqd7nQNXu1wQXBeu9I7wppmdTCmdMbOTwNlGo1LK7ILULXXh9Vty2Twquu9ba6UwqY1gYhN4NoKmXveyPsw0Y5uorR3nwMxE9Hst6eQFoOl+mzBTZ5g4CN1DNprivcGyXia7WtRZ5gXmiY0w64ktslKue6klDkHL/xZWXirX6Zy9vmnhnwAemP/8APD4Fc4TBPuCJo9P/wj4v8DPm9mrZvYg8DngXjN7AfjH83YQ3LDUqkYppU9d5lcfu8Z7CYI9Y6FBd6llVL3tJaeHy2Cy9VOSGW6ab3E4LiO49Ll7pVmfPT1XfQT6jB1Icti9OLzvjCnm1bWdIUWppVF+o247j8I78vy+6ouOXQ5xs8flC5eXdB5N5u1lulajIDkZAnWcaaBk1wnIVLetic3QLu3HlY68qP9XdAEixCIIgBCEIABCEIIACEEIAmDBxjJmVIPtJddPlqe1WjflgVOXNvI6xcPzeRsoDVLNzqCOJCiswNRxyjNtymmsIoNDaQSqYdtZk/rBF8qt9C9KkOCk/oTX8Gg+71gcUNODTuYOmUf32ho6Rq3WQ5Yx3iG9mTwDqZz31rQklRrYDZJPTOQ1rp90aliPnL8Xh7gjBAEhCEEAhCAEAbDoLBZVor2xrWTO+stFn+qc2A1v5wdxjr1S6pudkWS/PpLL9/hQuZfZkgR9OapkOz8TVOi1LeccSP98Pm//QiW/Lz1Q7VHeZ7qUK8jrJ0qFWZ1Lk8NyMKfnuNTka68SXb69WX4vdtZ3z5jtBdSpXdFyIg3VvGpiExSHeSRj9uRgOWbtlsh0FwSNCUEIAkIQggBYtB8hJWy6rWQ6BWfoncsvDn6S/37pXBk51ruYK6UHX811yeGx8kH8xnGpzHOs1GOnB1QnzdsdR/etOqr8yvNxJ+P0dFlsgpvztneQXYPstJJN2zlUr76SwgfgVYEVW2Omh268RHL6Fngxj5oU4Aq+kks7w0kGcSgq5gRBY0IQgoAQhCAAQhCCAFj0CbVOi8nqthNtNigNmckhdQzlfYbHSgu7dzG/1rsgJV7XSgN7cL7eiJ1JUr1qKZ9n3HOC1CoN1JO2c0pMnVLqIFx+oXTCdTbyidqjvI9NS8NxfCR/aLB+c/7xa+AewFR8nur4amTkOl63pEk3NDDPs3GLQL3d9wYwGzTLEBJ3hCAgBCEIgBCEIAAWbCPMei0u/cx2pNfYSYVaLUuG5kIPd7I8vyPOJDnY4iaSE129d6nstCZ+uN7NG1l7vFEeLJpq2dcDcoBmXCq//Yv52ktv5fp+Z60sl2VSdqs1zD1b7QvrxZjumbw9OJtHI46PlllFhqv5n8j6ifz9VxsCSv3fQ9/tJraGZvP2smMU6zSLuYs7QhBACEIQACEIQQAs2EaouvkBa++AeUvKly6/lrePP1uehll66S1ZSOyMA2WVnfGJ/BSHHoYBqPr5tRMrud59Vp9rA7O+VOI50CACTZPjaZbwm5y9FcF9MmUqDbCZmDSzfr2O3R6KT0ZsqZYT3FfYfl55WaHwr7jvU/Ei68c0TDQed4QgIAQhCIAQhCAAQhCCAFh00F07zzTgOTt653PZPPbd3Jm09EJZpSoNckdQ6ksw2fEyXfjoiKSbP1p+Jwxuu5i1b16+lLXPnnfSJoi9NpWgr+TVjpKAv4kY2NPS1i+ycKhDyntvtbqUWqiuI0yM2M6GOC83nSFyes7bf31mOy/lvkxRl+YeaHkn6Lx+zboFwU83IQhBQLMaareZ2VNm9pyZfc/MPj2/vmpmT5rZC/P/tZ5JENwwNLERpsBvpZS+ZWaHgL82syeBXwe+llL6nJk9DDwMfKZusuSVW9r5+xofz9ovnSyuXTolJV2XtAyRt1DeXP9Aefjl7r+XR6mtTXJbpKrK75EkmS5mcuCkcpxYekCpJTF2ni6senc1EH3fyehwJfd/kyDByUo+7/hYE12+gaNLz9xMnENPWu63Qda9a+ZQSymdSSl9a/7zJeB54BRwH/DovNujwP3NlgyC/cf7+o4ws9uBjwBPAydSSu9+Zb4BnLimOwuCBdJYEMzsIPCnwG+klLLniimlxGVuQmb2kJk9Y2bPzNbLGPkg2A80EgQz67IlBH+YUvrK/PKbZnZy/vuTQPmAH0gpPZJSOp1SOt0+UD7PD4L9QK2xbGYGfAF4PqX0uzt+9QTwAPC5+f+PN1mwtcPgSam8iczEGXPh5yTzwimnJJKmQJd526P6tORHb3+n6NMTb8zbm/JgzLHsU293C648cQeVnvKSeTUid+va7n28Ulipp06sektSjf+iHrX3cEOM2roHJFDWWfZOrBVLa61mL0OIZ6g7NHlq9CvAvwT+1sy+Pb/279kSgD82sweBHwG/2mjFINiH1ApCSunr+HIP8LFru50g2BvCsxwELLp01Aw66zvb5Y1m80SuCJ6/K9fTbbl0fLGevwwb1eub0+V8neMHyidaF8e512pjlB/xSl7Qlyqy0jZHd9c+7Y5k+zvoZKDT1zysT9egNoEt1UekJcnUp0F4NCjd6+kTxWevppWr7+sc+nvPCVfO4xF3hCAgBCEIgBCEIAAWbCO0JnDgzLai5x2aGEkJp96xvMbreL3MLlcEW4l46yEWgMGptay92t8o+pwb5Q/4J9NcD68m3ukXCQwTfb/l2AitlmS2ljHmRJNN22pH5C+6mjgZAWsuJMdmQ7NUaB/veaL6J5x5Naiuib7fxPYoF2rQh7gjBAEQghAEQAhCEAAhCEEALNxYThw4s338qr1ZWsvn7soN1F4/P641dQzUSozJlgS+HTpYplq44+jbWbvfLvcynOYBf5UacA2yKJgYjq126eHRxBadTt6n64yZSp+ZOL5GVh7Lm43kvVMnnGegqhNLjWfXj6epPBxjWa41yd7oJQDJxjjBfU2D7uKOEASEIAQBEIIQBMCig+6qRHtjWxdvjUu9XLMzHO2Pa+edTPKXsXooD6A7OihthGPiQKscpfSSBNlNxvJ2jR2nlcxTtcQJp3o6pdNNHWiDrhccJ2P01/2y3JQm1J/pay6HYDU1nbxsEwXeuRw1CkSXb3lBd3UBdN5WwqEWBM0JQQgCQhCCAFiwjYBB6m3L3qxXBtBpednpTLLY6UERYHmQa7/L3VzZHbRL5fdAJx9zdnio6DMcix9Bnru3Rk6mOw2qU/3YsSvYyOcdyWGXTqdUmHud3G7oiK+h7SjZbQnUG0nb9dGM5Zr6BDw7Se0GNwNdzeEpz0YoatJK23lrK+8glEPcEYKAEIQgAEIQggAIQQgCYOGlo4zJgU7WLhCnyYVLuYfNnMCqpQO5w0ydY71W6YkZSx2l8+OyvlFhmKuzbKm06FoHc8NcX2HlGJftdclSJ6nYN/vlQ4XWwXxtDczzTrXpXtR4Tl4WiDwTPpV8Zu4YNai9w2b6ORYJAutPqGlAnRd0V+MPfI+4IwQBIQhBAIQgBAGwYBuhahujI9sOGk8NbG/mF2fiXDpwKM9q4a4jE08dRfHH63lm67c2ypT1ldoImnnBy7qnc2xIRjonu4Rm6zYp4TpcLg/ZjLqytujybcdGKJJAuLWWZExdFyejduFUdDMCSlszaHtvrf69FIF7zpCwEYKgOSEIQUAIQhAAi/YjtGByYFvR0zKqAC05h6OHVpZ75SA9YDKd5Dr1CxvHizHrm3LoZtOpQSuHaDoX87adL4PUDrye76X/Tr7/9VvK7x5xaRTvi/oZAGaHJbOdlrp1gu60j/pJklcBSP0E2sd7dl8XeOhc8zKjF0Nqvra9DNpuxnKHuCMEASEIQQCEIAQB0EAQzGxgZt8ws++Y2ffM7LPz63eY2dNm9qKZfcnMyoCYILhBaGIsj4B7Ukpr83rLXzez/w38JvD5lNJjZvb7wIPA7+06k0FVU+GoJQFb6lfZHJdGrdpiw2HeZ3JuUIzprOUb6TnJMjrrErx3Kf+9GsIAKy/n2TE0U0drVp6EGx3O1xkdkeC+vhNAJ8alGr5FVj5KY1j7NDnLVTjYvEFdeV+8bHNFenkpa+UY7rUn1DwPbYPSttDgjpC2eLeYQHf+LwH3AF+eX38UuL/RikGwD2lkI5hZe15j+SzwJPAScD6l9O7X3avAqcuMfcjMnjGzZ6abZcG+INgPNBKElNIspfRh4FbgbuAXmi6QUnokpXQ6pXS6s1TG8wTBfuB9OdRSSufN7Cngl4EjZtaZ3xVuBV6rnwCyMzJepVXR1See3ieMRmITSHmpruP46l3I5+2UlaPoXcw32FuXMlDT8gVcuDPP5j0T80SdZwCTQ3IQ54To2CuO51HQ4ETvAJPq90kcbN4hm8Lxpf4176u0iRNLFf66VNfOvIXN4AUaXqugOzM7bmZH5j8vAfcCzwNPAZ+cd3sAeLzZkkGw/2hyRzgJPGpmbbYE549TSn9mZs8Bj5nZfwKeBb5wHfcZBNeVWkFIKf0N8BHn+sts2QtBcMMTnuUgYNEpHyEzeJzkEnTz8sdsOie6lCLbhKRiTI4Tb3xYSjo1SG+uGRymg3LMcFX65LYz04OlQTdZkTfikKRz7Jdp4dXQ1cjSlmOxFhGq6sRqUNq4GOOdUFML1TttJg61JtGnRV3o4sRa/ZjLEXeEICAEIQiAEIQgAPbCRtipszkOtc5mfjGJjTBTPZeybKpmWpsedkq6LuV694aTTW66nK/Vlgx0nrNmptNIn8o5CJe6Yq/Iqby2o4dXtntKd3WwgeMwE6PAzWqh6dublGutO9WGU15WPyLvtJm+pCZf481i7uKOEAQQghAEQAhCEAALLy+b2wCeHwFNZCfZo93Ma5phWprdI/XZ8aa9UnkfH5USruJr8Pav/oiqq5Fu5RgT26Nazz+WkfOMXZ/fV+pv8Z7LqxtBAvOS89C9zGJRTlugwXHeXuqCKZ2v6NKnUdehWSzfZZYLgr97hCAEASEIQQCEIAQBsGBjuTVLDN7ZtjBTq96S0WwT1XHPihKnTz+31vpO0NrGep5HPS2Vlm/VkpSPmhZeSyRRGsdewJ9S1GtWg9spN1X1ao6BeY4vScXYKCNF3bzeGDWOnYcKXnrGbFpn+3VZ4T0KR91liDtCEBCCEARACEIQAIsOuqugPdpWDmd9r4yS6Pfn8i2Ob3NkVxxDrYEE1Ik9ANB6PU8vkQal0tp/O1fwl9+QdcbOIZuDkrVuVX/vZK3ThA7iYPMODc302u6VcOfX5DU2sRGK+rj1NoKWfdX21rUGa9dspdD/vawojh3nEXeEICAEIQiAEIQgABZdOqoNk4PbenfVKfW39jBXHpfO5orfulfiqcjgJlnszpQ2wuEf5u2qW34ntCb5xN0NeQ7vPaof5n36klFPD/cDjA/LXrT0kkO7OGSjc5RjKvHbJOetVApfiR6oaZRCu0EXDQj0fA/iDlLbyR0TpaOCoDkhCEFACEIQACEIQQAs2qFmxnSwLXueoWVVfnH5rFhAQ0d2NdBtnDvCBmcdh84sH9P2TptJHzW82pPyBVRddSblfQ694mSge0OccFJKanzIcaiJ/V+Ul/IcamLoJjnl5pVrUuO4Na43UItAwwblm/RvwavB3R6qo1HGlLGVjYIeIe4IQQCEIAQBEIIQBMCibYQE7R2BauqwAuisT3ZttzfLOmwzPXgjB13aTunYtgTMubqkbE+zX0+POrp7b3eHU/dS+ZqX38r3338n77N5vPyYNuWA0lgyddPzDLDd28nxfLWKALpy2jq8LBaFfSK2iGYVhNIG0M9VHW5b6zTbY9wRgoAQhCAA3ocgzGstP2tmfzZv32FmT5vZi2b2JTMrs+gGwQ3C+7ERPs1WNc2Veft3gM+nlB4zs98HHgR+b7cJrEpZUF1rUiqcrQ1R/EZ5u//2oWLMxuruz8P1mTvAhTvz74DNU6WCaYP8IXmTrG82lAP/F/N1Omul7rt5PI9+0+fjWnWnCeZVpJX3oTgw4xxiaXL4pW6MW8hmVuMTGJVjtPRw4WvwPo9rmQ3bzG4F/inwP+dtA+4Bvjzv8ihwf7Mlg2D/0VQ1+i/Av2M7q+Ux4Py82DjAq8Apb6CZPWRmz5jZM5Px+lVtNgiuF00Kjv8z4GxK6a+vZIGU0iMppdMppdPdXvnoMwj2A01shF8B/rmZfQIYsGUj/FfgiJl15neFW4HXrt82g+D60qTg+G8Dvw1gZv8I+LcppX9hZn8CfBJ4DHgAeLx2rhZUOxxOXmCVYsPcQjrwemn9bNy5e6YCLSULMLo5t+g6K6XXTUdVUo4prZVvX/cdMY7XNdCt3N9E7P+k6dqdk2StkRibenrLcWKpsVlpnJ6Xfl4MXzeVv6JvnJehXlPsi3HsBdAVBrXjkFXUwXk5rsaP8BngN83sRbZshi9cxVxBsKe8rxCLlNJfAn85//ll4O5rv6UgWDzhWQ4C9uBgTpa5wsmGXQ3yLbXGuRdo+ayjPHqHdXYwXSqvdS5Ilu2NQdEnSeCa6uWdtXLd3oW8rYFhnnOsSEAnAXSVVy/LNGhQS996pWLzpmaBa5I5Qp1wGjy3NU+TErQypthbOaQ13f2gVOUF2EXpqCBoTghCEBCCEATAwsvLpvxAjD7IBmhpbdh8i4M3N4oh/bdWsvboeK7sVs4hlb487+++2eAgiGSx855j63P2mfgAKj1A46ChiC2v7Kt+hTXQhQsfgAbHeTbCTG0PmdM5QKP6vuc7KQLz9EU7B4C0wtJM4529KjtRMScImhOCEASEIAQBEIIQBMAeZLHYaWCqgwTAJmLdjCWLxfpmMebgK2osSwcnzbqmXu+uldtdeju32NojcWI5795kuSXt+qC7IrBNjc0G2eQqMRy9tPD6tVekWXcM38IJ18DxpY4tL7tEEUDXJLhPU9/rOo6B7WUj9Ig7QhAQghAEQAhCEACLLh3Vgll/W9FrD8s+tiEnNC7l55zTqExvcPT7+UTnfz4P1PMcapU4ukZOSSerxOm2Lg41T3fXMq8aQOdVvqrLxubFzxVlX/Oml71BVWhr4IRTvbvRwRyh7WSkqDvwo9nKAZJsWPd/JVn43lv/yocGwU8PIQhBQAhCEAAhCEEA7PEJNZuW1o2JcVytSXujjD7t/jDPJLP8+p1Ze/0DzjpinHlG7OZxKeEkJZ00K8TWxHlzNti9DTDr7+6oa1Q/WNteYG9d+saGp7myKRp8lXqOx4IGRriW4dINew7apsQdIQgIQQgCIAQhCIA9PqHWHpbRWGmSR2MlCbrDyehQnTuftQ+9kiucG6e80kV5e3S0tCOSlmxVnDTqGkym+nFyAgBVv09SLtcmzjpj1Y8blH1VB5T+3vlarDMbPCeWvrfevEWSjSLrnrOWBiPK34IXABgn1ILgfRCCEASEIAQBsGg/QgWd9W2lrSgTBYUNYF1Vsj2lNL+28oM83dxP/sHRYsh0ReY5WKbm7g5ypXMyyveSxuX3yGwi13r5OuZkhks6RtEST1Aq7xp05+rYu5eK9fwiGjDXJHtG3aEbb60ii10D30lxgMnbS0PfQtwRgoAQhCAAQhCCAAhBCAJgLxxqO51oU8+KEm9MO2/bkpPjXdd57WzW7r+9WvSZ3JRbXt2+49xTY0yN2qnzPaK2mTi6kuOEY6ZGrKZrKIco6mzyUrOrgaop611jeZxPXKSs9JxwerqsQQBgmX7emVdfowTh6Qm290PcEYKAEIQgAEIQggAA08Cl67qY2U+AHwE3AW8tbOGr40baK9xY+92Lvf5MSklzIS5WEN5b1OyZlNLphS98BdxIe4Uba7/7aa+hGgUBIQhBAOydIDyyR+teCTfSXuHG2u++2eue2AhBsN8I1SgIWLAgmNnHzewHZvaimT28yLWbYGZfNLOzZvbdHddWzexJM3th/n95uGEPMLPbzOwpM3vOzL5nZp+eX9+v+x2Y2TfM7Dvz/X52fv0OM3t6/jfxJTPTWpkLYWGCYGZt4L8D/wS4C/iUmd21qPUb8gfAx+Xaw8DXUkofBL42b+8HpsBvpZTuAj4K/Kv5+7lf9zsC7kkpfQj4MPBxM/so8DvA51NKdwLvAA/uxeYWeUe4G3gxpfRySmkMPAbct8D1a0kp/RVwTi7fBzw6//lR4P6FbuoypJTOpJS+Nf/5EvA8cIr9u9+UUnq3QFd3/i8B9wBfnl/fs/0uUhBOAa/saL86v7bfOZFSOjP/+Q3gxF5uxsPMbgc+AjzNPt6vmbXN7NvAWeBJ4CXgfErp3djTPfubCGP5fZC2HrHtq8dsZnYQ+FPgN1JKF3f+br/tN6U0Syl9GLiVLQ3hF/Z4S++xSEF4DbhtR/vW+bX9zptmdhJg/v/Zmv4Lw8y6bAnBH6aUvjK/vG/3+y4ppfPAU8AvA0fM7PrXpuEAAADISURBVN1zMXv2N7FIQfgm8MH5U4Ie8GvAEwtc/0p5Anhg/vMDwON7uJf3MDMDvgA8n1L63R2/2q/7PW5mR+Y/LwH3smXXPAV8ct5t7/abUlrYP+ATwA/Z0g3/wyLXbri/PwLOABO29NUHgWNsPX15Afg/wOpe73O+13/IltrzN8C35/8+sY/3+0vAs/P9fhf4j/PrPwt8A3gR+BOgvxf7C89yEBDGchAAIQhBAIQgBAEQghAEQAhCEAAhCEEAhCAEARCCEAQA/H9OLysTmIjq7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "print(lfw_people.target_names)\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "\n",
    "m, h, w = lfw_people.images.shape\n",
    "plt.imshow(X[0].reshape(h, w))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "8DnVfrZt2get",
    "outputId": "685401b1-1f96-4bf5-e82a-8db46cfaa3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       1.00      0.25      0.40        24\n",
      "     Colin Powell       0.73      0.80      0.77        45\n",
      "  Donald Rumsfeld       0.83      0.52      0.64        29\n",
      "    George W Bush       0.68      0.97      0.80       134\n",
      "Gerhard Schroeder       0.59      0.40      0.48        25\n",
      "      Hugo Chavez       1.00      0.33      0.50        24\n",
      "       Tony Blair       0.79      0.66      0.72        41\n",
      "\n",
      "         accuracy                           0.72       322\n",
      "        macro avg       0.80      0.56      0.61       322\n",
      "     weighted avg       0.76      0.72      0.69       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spJTmQPF2gez"
   },
   "source": [
    "6.10 支持向量机与回归问题。  \n",
    "本章中介绍的软间隔支持向量机算法是分类问题算法。然而，也可以将其拓展到回归问题中。在一个回归问题中，设$S=\\left \\{ (x^{(1)}, y^{(1)}),(x^{(2)}, y^{(2)}), \\dots (x^{(m)}, y^{(m)}) \\right \\}$为m条训练数据。回归问题的支持向量机模型假设为线性模型$h_w(x) = \\left \\langle w, x \\right \\rangle + b$，任务是计算如下问题的最优解$w^*、b^*$:  \n",
    "$$\n",
    "\\min \\limits_ {w, b, \\xi ,\\eta } \\frac{1}{2} \\left \\| w \\right \\|^2 + C\\sum _{i=1}^{m} (\\xi _i + \\eta _i) \\\\\n",
    "约束：\\left \\langle w, x^{(i)} \\right \\rangle + b - y^{(i)} \\leq \\xi _i,\\qquad i=1,2,\\dots , m \\\\\n",
    "y^{(i)} - \\left \\langle w, x^{(i)} \\right \\rangle -b \\leq \\eta  _i ,\\qquad i=1,2,\\dots , m \\\\\n",
    "\\xi _i \\geq 0,\\qquad i=1,2,\\dots , m \\\\ \n",
    "\\eta _i \\geq 0,\\qquad i=1,2,\\dots , m\n",
    "$$\n",
    "(1)请描述式(6.70)中优化问题的对偶问题，并设计求解对偶问题的坐标下降算法。\n",
    "(2)请设计直接优化式(6.70)的梯度下降算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SNnIT5kiGAw"
   },
   "source": [
    "（1）式(6.70)的拉格朗日函数如下\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&L(w,b,\\xi,\\eta,\\lambda,\\beta,\\lambda^*,\\beta^*)\\\\\n",
    "&=\\frac{1}{2}\\|w\\|^2+C\\sum_{i=1}^m(\\xi_i+\\eta_i)-\\sum_{i=1}^m\\lambda_i^*\\xi_i-\\sum_{i=1}^m\\beta_i^*\\eta_i  \\\\\n",
    "&+\\sum_{i=1}^m\\lambda_i(\\langle w,x^{(i)}\\rangle+b-y^{(i)}-\\xi_i)+\\sum_{i=1}^m\\beta_i(y^{(i)}-\\langle w,x^{(i)}\\rangle-b-\\eta_i) \\qquad\\qquad (1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "令$L(w,b,\\xi,\\eta,\\lambda,\\beta,\\lambda^*,\\beta^*)$对$w,b,\\xi_i,\\eta_i$的偏导数为0可得\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "&w=\\sum_{i=1}^m(\\beta_i-\\lambda_i)x^{(i)}\\quad\\qquad(2)\\\\\n",
    "&0=\\sum_{i=1}^m(\\beta_i-\\lambda_i)\\ \\ \\ \\ \\qquad\\qquad (3)\\\\\n",
    "&C=\\lambda_i+\\lambda_i^*\\qquad \\quad \\quad \\ \\ \\  \\qquad (4)\\\\\n",
    "&C=\\beta_i+\\beta_i^*\\qquad \\quad \\quad \\ \\ \\ \\ \\qquad (5)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "将式(2)-(5)代入(1)，即可得(6.70)中优化问题的对偶问题\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\max_{\\lambda,\\beta}\\sum_{i=1}^my^{(i)}(\\beta_i-\\lambda_i)-\\frac{1}{2}\\sum_{i,j=1}^m(\\beta_i-\\lambda_i)(\\beta_j-\\lambda_j)\\langle x^{(i)}, x^{(j)} \\rangle\\\\\n",
    "&约束：\\sum_{i=1}^m(\\beta_i-\\lambda_i)=0,\\ \\ \\ \\ \\ \\ 0\\le\\lambda_i, \\beta_i \\le C\n",
    "\\end{aligned}\n",
    "$$\n",
    "上述过程需要满足KKT条件，即要求\n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "&w=\\sum_{i=1}^m(\\beta_i-\\lambda_i)x^{(i)}\\\\\n",
    "&(C-\\lambda_i)\\xi_i=0,\\ \\ (C-\\beta_i)\\eta_i=0  \\\\\n",
    "&\\lambda_i(\\langle w,x^{(i)}\\rangle+b-y^{(i)}-\\xi_i)=0\\\\\n",
    "&\\beta_i(y^{(i)}-\\langle w,x^{(i)}\\rangle-b-\\eta_i)=0\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "当$\\langle w,x^{(i)} \\rangle + b - y^{(i)} - \\xi_i = 0$时$\\lambda_i$取非零值，当$ y^{(i)}-\\langle w,x^{(i)} \\rangle - b -\\eta_i = 0$时$\\beta_i$取非零值，约束$\\langle w,x^{(i)} \\rangle + b - y^{(i)} - \\xi_i = 0$和$ y^{(i)}-\\langle w,x^{(i)} \\rangle - b -\\eta_i = 0$不能同时成立，因此$\\lambda_i$和$\\beta_i$中至少有一个为零。\n",
    "\n",
    "若$0<\\lambda_i<C$，则必有$\\xi_i=0$，进而有\n",
    "$$\n",
    "b=y^{(i)}-\\langle w,x^{(i)} \\rangle=y^{(i)}-\\sum_{j=1}^m(\\beta_j-\\lambda_j)\\langle x^{(j)},x^{(i)}\\rangle\n",
    "$$\n",
    "采用一种更鲁棒的方法：求平均值，假设满足要求的样本集合为S\n",
    "$$\n",
    "b=\\frac{1}{|S|}\\sum_{s \\in S}(y^{(s)}-\\sum_{j=1}^m(\\beta_j-\\lambda_j)\\langle x^{(j)},x^{(s)}\\rangle)\n",
    "$$\n",
    "(2)\n",
    "不会做，以下是瞎写的^_^\n",
    "$$\n",
    "\\frac{\\partial L }{\\partial w} = w + \\sum_{i=1}^m (\\lambda_i-\\beta_i) x^{(i)}\\\\\n",
    "\\frac{\\partial L }{\\partial b} = \\sum_{i=1}^m(\\lambda_i-\\beta_i)\\\\\n",
    "w \\leftarrow w - \\frac{\\partial L }{\\partial w}\\\\\n",
    "b \\leftarrow b - \\frac{\\partial L }{\\partial b}\\\\\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ch06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
